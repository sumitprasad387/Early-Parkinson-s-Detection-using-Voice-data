{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa6a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from pyroomacoustics import room\n",
    "from pyroomacoustics.room import ShoeBox\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "717e0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_original  = r'C:\\Users\\AL56170\\Downloads\\Parkinson_dataset\\Parkinson_negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f5f8a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_generated = 'u'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ab1df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_db=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d418fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(audio_original):\n",
    "    audio_path = os.path.join(audio_original,file)\n",
    "    audio,sr=sf.read(audio_path)\n",
    "    noise_samples=np.random.randn(len(audio))\n",
    "    signal_power= np.mean(audio**2)\n",
    "    noise_power = np.mean(noise_samples**2)\n",
    "    scale_factor= np.sqrt(signal_power/(noise_power*(10**(snr_db/10))))\n",
    "    noisy_audio = audio + scale_factor*noise_samples\n",
    "    augmented_filename= f\"augmented_{file}\"\n",
    "    augmented_filepath = os.path.join(audio_generated,augmented_filename)\n",
    "    sf.write(augmented_filepath,noisy_audio,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bffec283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "time_stretch_factor=1.5\n",
    "for file in os.listdir(audio_original):\n",
    "    file_path = os.path.join(audio_original, file)\n",
    "    audio,sr = librosa.load(file_path,sr=None)\n",
    "    time_stretched= librosa.effects.time_stretch(audio, rate=time_stretch_factor)\n",
    "    output_file = f\"time_stretched_{file}\"\n",
    "    output_path = os.path.join(audio_generated, output_file)\n",
    "    sf.write(output_path, time_stretched, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4eff6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement shutil (from versions: none)\n",
      "ERROR: No matching distribution found for shutil\n"
     ]
    }
   ],
   "source": [
    "pip install shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0783f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_files(source_folder, destination_folder):\n",
    "    # Get a list of all audio files in the source folder\n",
    "    audio_files = [file for file in os.listdir(source_folder) if file.endswith('.wav')]\n",
    "\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "        # Get the source and destination file paths\n",
    "        source_path = os.path.join(source_folder, audio_file)\n",
    "        destination_path = os.path.join(destination_folder, audio_file)\n",
    "\n",
    "        # Copy the file from the source to the destination folder\n",
    "        shutil.copy(source_path, destination_path)\n",
    "\n",
    "def main():\n",
    "    # Set the paths to the source and destination folders\n",
    "    source_folder = r'C:\\Users\\AL56170\\Downloads\\Parkinson_dataset\\Parkinson_negative'\n",
    "    destination_folder = 'u'\n",
    "\n",
    "    # Call the copy_files function\n",
    "    copy_files(source_folder, destination_folder)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6aded8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_original = 'u'\n",
    "target_duration = 200\n",
    "for file in os.listdir(audio_original):\n",
    "    if file.endswith(\".wav\"):  # Adjust file extensions as needed\n",
    "        file_path = os.path.join(audio_original, file)\n",
    "        audio,sr = librosa.load(file_path,sr=None)\n",
    "        current_duration=librosa.get_duration(y=audio,sr=sr)\n",
    "        if current_duration<target_duration:\n",
    "            pad_length = int((target_duration - current_duration)*sr)\n",
    "            padded_audio=np.pad(audio,(0,pad_length), mode='constant')\n",
    "            sf.write(file_path,padded_audio,sr)\n",
    "        elif current_duration>target_duration:\n",
    "            num_samples = int(target_duration*sr)\n",
    "            truncated_audio = audio[:num_samples]\n",
    "            sf.write(file_path, truncated_audio, sr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e6ff802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Features Shape: (290, 17227, 15)\n"
     ]
    }
   ],
   "source": [
    "audio_folder_positive = 'p'\n",
    "audio_folder_negative = 'u'\n",
    "n_mfcc = 15\n",
    "hop_length=512\n",
    "win_length=512\n",
    "positive_features = []\n",
    "negative_features = []\n",
    "for file_name in os.listdir(audio_folder_positive):\n",
    "    if file_name.endswith('.wav'):\n",
    "        audio_path = os.path.join(audio_folder_positive, file_name)\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, win_length=win_length)\n",
    "        positive_features.append(mfcc.T)  # Transpose for shape compatibility\n",
    "\n",
    "for file_name in os.listdir(audio_folder_negative):\n",
    "    if file_name.endswith('.wav'):\n",
    "        audio_path = os.path.join(audio_folder_negative, file_name)\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, win_length=win_length)\n",
    "        negative_features.append(mfcc.T)  # Transpose for shape compatibility\n",
    "X = np.concatenate((positive_features, negative_features), axis=0)\n",
    "\n",
    "print(\"Combined Features Shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b8866ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X.reshape(X.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ae58e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.concatenate((np.ones(len(positive_features)),np.zeros(len(negative_features))),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c74d59b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290,)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9072345a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_)\n",
    "X_input = scaler.transform(X_) \n",
    "joblib.dump(scaler,\"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d3c41734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.16294301, -1.59844446, -1.61548591, ...,  0.70355621,\n",
       "         0.70869669,  0.72670729],\n",
       "       [ 1.54753864, -1.6685437 , -1.11332476, ..., -1.83469178,\n",
       "        -1.84399993, -1.86839488],\n",
       "       [ 1.0678463 , -0.9446761 , -1.01356304, ...,  0.29569391,\n",
       "         0.29851268,  0.30970928],\n",
       "       ...,\n",
       "       [-0.15965591,  1.59410214, -0.72041357, ...,  0.05792151,\n",
       "         0.0593868 ,  0.06661101],\n",
       "       [-1.41462278, -0.49542966,  0.44288453, ..., -0.24070817,\n",
       "        -0.24094279, -0.23870767],\n",
       "       [-0.60518223,  0.33194429,  0.83761257, ..., -0.15430269,\n",
       "        -0.15404545, -0.15036678]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input = np.concatenate((X_input,X__input),axis=1)\n",
    "X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "36dd45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
    "\n",
    "X_train,X_test, Y_train,Y_test=train_test_split(X_input,Y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8eefc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d4cc7d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9137931034482759"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(kernel = 'linear',random_state = 42)\n",
    "classifier.fit(X_train,Y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "73c14951",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "23184696",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7e96d33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9137931034482759"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8786971d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.16294301, -1.59844446, -1.61548591, ...,  0.70869669,\n",
       "         0.72670729,  1.        ],\n",
       "       [ 1.54753864, -1.6685437 , -1.11332476, ..., -1.84399993,\n",
       "        -1.86839488,  1.        ],\n",
       "       [ 1.0678463 , -0.9446761 , -1.01356304, ...,  0.29851268,\n",
       "         0.30970928,  1.        ],\n",
       "       ...,\n",
       "       [-0.15965591,  1.59410214, -0.72041357, ...,  0.0593868 ,\n",
       "         0.06661101,  0.        ],\n",
       "       [-1.41462278, -0.49542966,  0.44288453, ..., -0.24094279,\n",
       "        -0.23870767,  0.        ],\n",
       "       [-0.60518223,  0.33194429,  0.83761257, ..., -0.15404545,\n",
       "        -0.15036678,  0.        ]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset = np.concatenate((X_input,Y.reshape(-1,1)),axis=1)\n",
    "final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "51c92264",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cd63be7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.41570109e-01, -3.41586769e-01,  8.52407590e-02, ...,\n",
       "        -2.56941982e+00, -2.58291032e+00, -2.61958009e+00],\n",
       "       [ 9.50724483e-02, -2.15274394e-01,  6.74410760e-01, ...,\n",
       "        -1.87215421e+00, -1.88167562e+00, -1.90669644e+00],\n",
       "       [-1.20203018e+00, -5.65260053e-01,  4.30306882e-01, ...,\n",
       "        -6.86319107e-03, -5.76667896e-03,  3.75206684e-04],\n",
       "       ...,\n",
       "       [-4.84483838e-02,  2.39561275e-01, -5.41850105e-02, ...,\n",
       "        -5.50117033e-01, -5.52112920e-01, -5.55046970e-01],\n",
       "       [-1.08461738e+00,  2.82878816e-01,  1.44368422e+00, ...,\n",
       "         2.50257832e+00,  2.51795948e+00,  2.56602566e+00],\n",
       "       [ 7.55871236e-01,  2.82522440e+00,  3.82806994e-02, ...,\n",
       "        -7.43166171e-01, -7.46260963e-01, -7.52420212e-01]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final = final_dataset[:,:-1]\n",
    "X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6687ab2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_final = final_dataset[:,-1]\n",
    "Y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f267996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing cross validation\n",
    "model=SVC()\n",
    "model_predict=cross_val_predict(model,X_final,Y_final,cv=10)\n",
    "model_score=cross_val_score(model,X_final,Y_final,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5a19b8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8758620689655172"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "81f6d9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       1.])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d9305aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[142,   2],\n",
       "       [ 34, 112]], dtype=int64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "\n",
    "confusion_result = confusion_matrix(Y_final,model_predict)\n",
    "confusion_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9215754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Centroid Features Folder 1 Shape: (146, 17227)\n",
      "Spectral Bandwidth Features Folder 1 Shape: (146, 17227)\n",
      "Spectral Contrast Features Folder 1 Shape: (146, 120589)\n",
      "Spectral Centroid Features Folder 2 Shape: (144, 17227)\n",
      "Spectral Bandwidth Features Folder 2 Shape: (144, 17227)\n",
      "Spectral Contrast Features Folder 2 Shape: (144, 120589)\n"
     ]
    }
   ],
   "source": [
    "audio_folder_1 = 'p'\n",
    "audio_folder_2 = 'u'\n",
    "spectral_centroid_features_folder1 = []\n",
    "spectral_bandwidth_features_folder1 = []\n",
    "spectral_contrast_features_folder1 = []\n",
    "\n",
    "spectral_centroid_features_folder2 = []\n",
    "spectral_bandwidth_features_folder2 = []\n",
    "spectral_contrast_features_folder2 = []\n",
    "\n",
    "def extract_spectral_features(audio_folder):\n",
    "    spectral_centroid_features = []\n",
    "    spectral_bandwidth_features = []\n",
    "    spectral_contrast_features = []\n",
    "    for file_name in os.listdir(audio_folder):\n",
    "        if file_name.endswith('.wav'):\n",
    "            audio_path = os.path.join(audio_folder, file_name)\n",
    "            audio, sr = librosa.load(audio_path, sr=None)\n",
    "            spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
    "            spectral_centroid_features.append(spectral_centroid)\n",
    "            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)\n",
    "            spectral_bandwidth_features.append(spectral_bandwidth)\n",
    "            spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)\n",
    "            spectral_contrast_features.append(spectral_contrast)\n",
    "    spectral_centroid_features = np.array(spectral_centroid_features)\n",
    "    spectral_bandwidth_features = np.array(spectral_bandwidth_features)\n",
    "    spectral_contrast_features = np.array(spectral_contrast_features)\n",
    "    spectral_centroid_features= np.squeeze(spectral_centroid_features)\n",
    "    spectral_bandwidth_features= np.squeeze(spectral_bandwidth_features)\n",
    "    spectral_contrast_features=spectral_contrast_features.reshape(spectral_contrast_features.shape[0],-1)\n",
    "    return spectral_centroid_features, spectral_bandwidth_features, spectral_contrast_features\n",
    "spectral_centroid_features_folder1, spectral_bandwidth_features_folder1, spectral_contrast_features_folder1 = extract_spectral_features(audio_folder_1)\n",
    "spectral_centroid_features_folder2, spectral_bandwidth_features_folder2, spectral_contrast_features_folder2 = extract_spectral_features(audio_folder_2)\n",
    "print(\"Spectral Centroid Features Folder 1 Shape:\", spectral_centroid_features_folder1.shape)\n",
    "print(\"Spectral Bandwidth Features Folder 1 Shape:\", spectral_bandwidth_features_folder1.shape)\n",
    "print(\"Spectral Contrast Features Folder 1 Shape:\", spectral_contrast_features_folder1.shape)\n",
    "\n",
    "print(\"Spectral Centroid Features Folder 2 Shape:\", spectral_centroid_features_folder2.shape)\n",
    "print(\"Spectral Bandwidth Features Folder 2 Shape:\", spectral_bandwidth_features_folder2.shape)\n",
    "print(\"Spectral Contrast Features Folder 2 Shape:\", spectral_contrast_features_folder2.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a019f2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.08158481e+04, 1.09878844e+04, 1.09766035e+04, ...,\n",
       "        1.35618636e+01, 1.35618636e+01, 1.35618636e+01],\n",
       "       [1.08286775e+04, 1.04418236e+04, 1.04281058e+04, ...,\n",
       "        6.38526087e+00, 6.38526087e+00, 6.38526087e+00],\n",
       "       [1.04081524e+04, 1.07166999e+04, 1.07997753e+04, ...,\n",
       "        1.24086801e+01, 1.24086801e+01, 1.24086801e+01],\n",
       "       ...,\n",
       "       [3.90713818e+03, 4.57032999e+03, 4.89727697e+03, ...,\n",
       "        1.17364061e+01, 1.17364061e+01, 1.17364061e+01],\n",
       "       [8.85150512e+03, 8.10808462e+03, 7.91660057e+03, ...,\n",
       "        1.08920652e+01, 1.08920652e+01, 1.08920652e+01],\n",
       "       [7.17603233e+03, 7.12789816e+03, 7.07805914e+03, ...,\n",
       "        1.11363668e+01, 1.11363668e+01, 1.11363668e+01]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p = np.concatenate((spectral_centroid_features_folder1,spectral_bandwidth_features_folder1,spectral_contrast_features_folder1),axis=1)\n",
    "X_n = np.concatenate((spectral_centroid_features_folder2,spectral_bandwidth_features_folder2,spectral_contrast_features_folder2),axis=1)\n",
    "X__ = np.concatenate((X_p,X_n),axis=0)\n",
    "X__.shape\n",
    "X__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "58f814d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.39589149,  1.45492464,  1.34693476, ...,  0.70355621,\n",
       "         0.70869669,  0.72670729],\n",
       "       [ 1.40111683,  1.22697511,  1.12781945, ..., -1.83469178,\n",
       "        -1.84399993, -1.86839488],\n",
       "       [ 1.22983983,  1.34172045,  1.27629497, ...,  0.29569391,\n",
       "         0.29851268,  0.30970928],\n",
       "       ...,\n",
       "       [-1.41797848, -1.22404158, -1.08165041, ...,  0.05792151,\n",
       "         0.0593868 ,  0.06661101],\n",
       "       [ 0.59582812,  0.25277102,  0.12451683, ..., -0.24070817,\n",
       "        -0.24094279, -0.23870767],\n",
       "       [-0.08658041, -0.15640143, -0.21046588, ..., -0.15430269,\n",
       "        -0.15404545, -0.15036678]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X__)\n",
    "X__input = scaler.transform(X__) \n",
    "X__input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00adea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a284e1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ac132b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290, 413448)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f4606c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_final.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ba0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Assuming you have 'X' with shape (n_samples, n_features) and 'y' with shape (n_samples,)\n",
    "# where n_samples is the number of samples and n_features is the number of features.\n",
    "\n",
    "# Perform Information Gain feature selection\n",
    "def information_gain_feature_selection(X, y, k):\n",
    "    # Calculate the Information Gain (mutual information) between each feature and the target variable\n",
    "    information_gain = mutual_info_classif(X, y)\n",
    "\n",
    "    # Sort the features based on Information Gain in descending order and select the top-k features\n",
    "    selected_features_indices = np.argsort(information_gain)[::-1][:k]\n",
    "    return selected_features_indices\n",
    "\n",
    "# Set the desired number of features to select\n",
    "num_features_to_select = 5000\n",
    "\n",
    "# Perform Information Gain feature selection\n",
    "selected_features_indices = information_gain_feature_selection(X_final, Y_final, num_features_to_select)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dcb8acd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_selected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_selected\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_selected' is not defined"
     ]
    }
   ],
   "source": [
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fcf3d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, Y_train,Y_test=train_test_split(X_final,Y_final,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b31d4ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9137931034482759"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(kernel = 'linear',random_state = 42)\n",
    "classifier.fit(X_train,Y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e4bcdc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.93      0.92        29\\n         1.0       0.93      0.90      0.91        29\\n\\n    accuracy                           0.91        58\\n   macro avg       0.91      0.91      0.91        58\\nweighted avg       0.91      0.91      0.91        58\\n'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classification_result  = classification_report(Y_test,y_pred)\n",
    "classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "942f8cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27,  2],\n",
       "       [ 3, 26]], dtype=int64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_result = confusion_matrix(Y_test,y_pred)\n",
    "confusion_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0ede9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing cross validation\n",
    "classifier = SVC(kernel = 'linear',random_state = 42)\n",
    "model_predict=cross_val_predict(classifier,X_final,Y_final,cv=10)\n",
    "model_score=cross_val_score(model,X_final,Y_final,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2b975dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8758620689655172"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8c8a0019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.95      0.93       144\\n         1.0       0.95      0.90      0.93       146\\n\\n    accuracy                           0.93       290\\n   macro avg       0.93      0.93      0.93       290\\nweighted avg       0.93      0.93      0.93       290\\n'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classification_result  = classification_report(Y_final,model_predict)\n",
    "classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a80585ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['parkinson_model1.pkl']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(classifier,\"parkinson_model1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5cc0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(scaler1,\"scaler1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6befa65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(scaler,\"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5b055f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
